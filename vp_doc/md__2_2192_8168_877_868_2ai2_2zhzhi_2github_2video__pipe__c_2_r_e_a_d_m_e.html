<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>VideoPipe: VideoPipe</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">VideoPipe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">VideoPipe</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md20"></a> 一个用于视频结构化的框架。它可以处理复杂任务，如流读取（从本地或网络）、视频解码、基于深度学习模型的推理（分类/检测/特征提取/...）、跟踪及行为分析、屏幕上显示（OSD）、通过中间件进行数据代理（如Kafka/Socket）、视频编码和流推送（RTMP或本地文件）。框架采用面向插件的编码风格，我们可以使用独立的插件，即框架中的Node类型，来构建不同类型的视频分析管道。</p>
<p><code>VideoPipe</code>类似于英伟达的DeepStream和华为的mxVision，但它更易于使用，更具备可移植性，并且对于像gstreamer这样难以学习（编码风格或调试方面）的第三方模块的依赖较少。该框架纯粹由原生C++ STL编写，并较少依赖于主流的第三方模块（如OpenCV），因此代码更易于在不同平台上移植。</p>
<p><img src="./doc/p1.png" alt="" class="inline"/></p>
<p><code>VideoPipe</code>可用于以下场合:</p><ol type="1">
<li>视频结构化</li>
<li>图片搜索（相似度检索）</li>
<li>人脸识别</li>
<li>安防领域的行为分析（如交通事件检测）、reID相关应用</li>
</ol>
<blockquote class="doxtable">
<p>&zwj;注意：<br  />
 VideoPipe是一个让计算机视觉领域中模型集成更加简单的框架，它并不是像TensorFlow、TensorRT类似的深度学习框架。 </p>
</blockquote>
<p><a href="https://github.com/sherlockchou86/video_pipe_c/assets/13251045/2cac8020-a4c4-4a7c-926b-a139a3b29161">https://github.com/sherlockchou86/video_pipe_c/assets/13251045/2cac8020-a4c4-4a7c-926b-a139a3b29161</a></p>
<p><a href="https://github.com/sherlockchou86/video_pipe_c/assets/13251045/b1289faa-e2c7-4d38-871e-879ae36f6d50">https://github.com/sherlockchou86/video_pipe_c/assets/13251045/b1289faa-e2c7-4d38-871e-879ae36f6d50</a></p>
<p><a href="https://github.com/sherlockchou86/video_pipe_c/assets/13251045/c0be8f6f-949a-4ab3-b0eb-9ac1496bee1d">https://github.com/sherlockchou86/video_pipe_c/assets/13251045/c0be8f6f-949a-4ab3-b0eb-9ac1496bee1d</a></p>
<p>播放器右下角全屏观看，<a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2_s_a_m_p_l_e_s.html">更多视频演示</a></p>
<h1><a class="anchor" id="autotoc_md21"></a>
主要功能</h1>
<ul>
<li>流读取。支持流行的协议，如udp（视频或图像）、rtsp、rtmp、文件（视频或图像）。</li>
<li>视频解码。支持基于opencv/gstreamer的视频解码（支持硬件加速）。</li>
<li>基于深度学习的推理。支持基于深度学习模型的多级推理，例如目标检测、图像分类、特征提取。你只需准备好模型并了解如何解析其输出即可。推理可以基于不同的后端实现，如opencv::dnn（默认）、tensorrt、paddle_inference、onnx runtime等，任何你喜欢的都可以。</li>
<li>屏幕显示（OSD）。支持可视化，如将模型输出绘制到帧上。</li>
<li>消息代理。支持将结构化数据（json/xml/自定义格式）以kafka/Sokcet等方式推送到云端、文件或其他第三方平台。</li>
<li>目标追踪。支持目标追踪，例如iou、sort跟踪算法等。</li>
<li>行为分析（BA）。支持基于追踪的行为分析，例如越线、停车判断。</li>
<li>录制。支持特定时间段的视频录制，特定帧的截图。</li>
<li>视频编码。支持基于opencv/gstreamer的视频编码（支持硬件加速）。</li>
<li>流推送。支持通过rtmp、rtsp（无需专门的rtsp服务器）、文件（视频或图像）、udp（仅限图像）、屏幕显示（GUI）进行流推送或结果展示。</li>
</ul>
<h1><a class="anchor" id="autotoc_md22"></a>
主要特点</h1>
<ol type="1">
<li>可视化管道，对于调试非常有用。管道的运行状态会自动在屏幕上刷新，包括管道中每个连接点的fps、缓存大小、延迟等信息，你可以根据这些运行信息快速确定管道的瓶颈所在。</li>
<li>节点之间通过智能指针传递数据，默认情况下是浅拷贝，当数据在整个管道中流动时无需进行内容拷贝操作。当然，如果需要，你可以指定深拷贝，例如当管道具有多个分支时，你需要分别在两个不同的内容拷贝上进行操作。</li>
<li>你可以构建不同类型的管道，支持单通道或多通道的管道，管道中的各通道是独立的。每个通道可以拆分成多个分支并行处理不同的任务，之后进行数据同步，再合并回一个分支进行输出。</li>
<li>管道支持钩子（回调），你可以向管道注册回调以获取状态通知（参见第1项），例如实时获取某个连接点的fps。</li>
<li>VideoPipe中已经内置了许多节点类型，但是框架中的所有节点都可以由用户重新实现，也可以根据你的实际需求实现更多节点类型。</li>
<li>支持动态操作管道，支持多线程并行操作，支持<code>热插拔</code>操作模式（管道无需先暂停，即插即用）。</li>
<li>整个框架主要由原生C++编写，可在所有平台上移植。</li>
</ol>
<h1><a class="anchor" id="autotoc_md23"></a>
帮助资料</h1>
<ul>
<li>sample code</li>
<li><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2nodes_2_r_e_a_d_m_e.html">node table</a></li>
<li><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2doc_2about.html">how VideoPipe works</a></li>
<li><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2nodes_2record_2_r_e_a_d_m_e.html">how record works</a></li>
<li><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2doc_2env.html">environment for reference</a></li>
<li>:blush: wait for update...</li>
</ul>
<h1><a class="anchor" id="autotoc_md24"></a>
扫码入群交流</h1>
<p><img src="./doc/vx.png" alt="" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md25"></a>
依赖</h1>
<p>平台</p><ul>
<li>Ubuntu 18.04 x86_64 NVIDIA rtx/tesla GPUs</li>
<li>Ubuntu 18.04 aarch64 NVIDIA jetson serials device，tx2 tested</li>
<li>Ubuntu 18.04 x86_64 Cambrian MLU serials device, MLU 370 tested (code not provided)</li>
<li>Wait for your test</li>
</ul>
<p>基础</p><ul>
<li>C++ 17</li>
<li>OpenCV &gt;= 4.6</li>
<li>GStreamer 1.20 (Required by OpenCV)</li>
<li>GCC &gt;= 7.5</li>
</ul>
<p>可选, 如果你需要实现自己的推理后端，或者使用除<code>opencv::dnn</code>之外的其他推理后端.</p><ul>
<li>CUDA</li>
<li>TensorRT</li>
<li>Paddle Inference</li>
<li>ONNX Runtime</li>
<li>Anything you like</li>
</ul>
<p><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2third__party_2trt__vehicle_2_r_e_a_d_m_e.html">如何安装CUDA和TensorRT</a></p>
<p><a class="el" href="md__2_2192_8168_877_868_2ai2_2zhzhi_2github_2video__pipe__c_2third__party_2paddle__ocr_2_r_e_a_d_m_e.html">如何安装Paddle_Inference</a></p>
<h1><a class="anchor" id="autotoc_md26"></a>
如何编译和调试</h1>
<ol type="1">
<li>运行 <code>git clone <a href="https://github.com/sherlockchou86/video_pipe_c.git">https://github.com/sherlockchou86/video_pipe_c.git</a></code></li>
<li>运行 <code>cd video_pipe_c</code></li>
<li>运行 <code>mkdir build &amp;&amp; cd build</code></li>
<li>运行 <code>cmake ..</code></li>
<li>运行 <code>make -j8</code></li>
</ol>
<p>编译完成后，所有的库文件存放在<code>build/libs</code>中，所有的Sample运行文件存放在<code>build/bin</code>中。在执行第4步的时候，可以添加一些编译选项：</p><ul>
<li>-DVP_WITH_CUDA=ON （编译CUDA相关功能，默认为OFF）</li>
<li>-DVP_WITH_TRT=ON （编译TensorRT相关功能和Samples，默认为OFF）</li>
<li>-DVP_WITH_PADDLE=ON （编译PaddlePaddle相关功能和Samples，默认为OFF）</li>
<li>-DVP_BUILD_COMPLEX_SAMPLES=ON （编译高级Samples，默认为OFF）</li>
</ul>
<p>比如需要开启CUDA和TensorRT相关的模块，可以运行 <code>cmake -DVP_WITH_CUDA=ON -DVP_WITH_TRT=ON ..</code>。如果只运行<code>cmake ..</code>，那么所有代码运行在CPU上。 </p><div class="fragment"><div class="line"># 开启全部</div>
<div class="line">cmake -DVP_WITH_CUDA=ON -DVP_WITH_TRT=ON -DVP_WITH_PADDLE=ON -DVP_BUILD_COMPLEX_SAMPLES=ON ..</div>
<div class="line"># 关闭全部（默认）</div>
<div class="line">cmake ..</div>
</div><!-- fragment --><p>如果要运行编译生成的Samples，先下载模型文件和测试数据：</p>
<ol type="1">
<li><a href="https://drive.google.com/drive/folders/1v9dVcR6xttUTB-WPsH3mZ_ZZMzD4wG-v?usp=sharing">谷歌网盘下载测试文件和模型</a></li>
<li><a href="https://pan.baidu.com/s/1jr2nBnEDmuNaM5DiMjbC0g?pwd=nf53">百度网盘下载测试文件和模型</a></li>
</ol>
<p>将下载好的目录（名称为vp_data）放在任何位置（比如放在<code>/root/abc</code>下面），然后在<code>同一目录</code>下运行Sample，比如在<code>/root/abc</code>下面执行命名：<code>[path to video_pipe_c]/build/bin/1-1-1_sample</code>即可运行1-1-1_sample。</p>
<blockquote class="doxtable">
<p>&zwj;注意： <code>./third_party/</code> 下面都是独立的项目，有的是header-only库，被VideoPipe直接引用；有的包含有cpp文件，可以独立编译或运行，VideoPipe依赖这些库，在编译VideoPipe的过程中会自动编译这些库。这些库也包含自己的Samples，具体使用方法可参见对应子目录下的README文件. </p>
</blockquote>
<h1><a class="anchor" id="autotoc_md27"></a>
如何使用</h1>
<ol type="1">
<li>先将VideoPipe编译成库，然后引用它.</li>
<li>或者直接引用源代码，然后编译整个application.</li>
</ol>
<p>下面是一个如何构建Pipeline然后运行的Sample(请先修改代码中的相关文件路径): </p><div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/vp_file_src_node.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/infers/vp_yunet_face_detector_node.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/infers/vp_sface_feature_encoder_node.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/osd/vp_face_osd_node_v2.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/vp_screen_des_node.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../nodes/vp_rtmp_des_node.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;../utils/analysis_board/vp_analysis_board.h&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">/*</span></div>
<div class="line"><span class="comment">* ## 1-1-N sample ##</span></div>
<div class="line"><span class="comment">* 1 video input, 1 infer task, and 2 outputs.</span></div>
<div class="line"><span class="comment">*/</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="1-1-1__sample_8cpp.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a>() {</div>
<div class="line">    <a class="code hl_define" href="vp__logger_8h.html#a7b026e0cb7b1f5bcee94784c7c94a736">VP_SET_LOG_INCLUDE_CODE_LOCATION</a>(<span class="keyword">false</span>);</div>
<div class="line">    <a class="code hl_define" href="vp__logger_8h.html#a773398f3b7212c837d3996bd4a8ebc2d">VP_SET_LOG_INCLUDE_THREAD_ID</a>(<span class="keyword">false</span>);</div>
<div class="line">    <a class="code hl_define" href="vp__logger_8h.html#a215e39f45255869a55a87042c9b13048">VP_LOGGER_INIT</a>();</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// create nodes</span></div>
<div class="line">    <span class="keyword">auto</span> file_src_0 = std::make_shared&lt;vp_nodes::vp_file_src_node&gt;(<span class="stringliteral">&quot;file_src_0&quot;</span>, 0, <span class="stringliteral">&quot;./test_video/10.mp4&quot;</span>, 0.6);</div>
<div class="line">    <span class="keyword">auto</span> yunet_face_detector_0 = std::make_shared&lt;vp_nodes::vp_yunet_face_detector_node&gt;(<span class="stringliteral">&quot;yunet_face_detector_0&quot;</span>, <span class="stringliteral">&quot;./models/face/face_detection_yunet_2022mar.onnx&quot;</span>);</div>
<div class="line">    <span class="keyword">auto</span> sface_face_encoder_0 = std::make_shared&lt;vp_nodes::vp_sface_feature_encoder_node&gt;(<span class="stringliteral">&quot;sface_face_encoder_0&quot;</span>, <span class="stringliteral">&quot;./models/face/face_recognition_sface_2021dec.onnx&quot;</span>);</div>
<div class="line">    <span class="keyword">auto</span> osd_0 = std::make_shared&lt;vp_nodes::vp_face_osd_node_v2&gt;(<span class="stringliteral">&quot;osd_0&quot;</span>);</div>
<div class="line">    <span class="keyword">auto</span> screen_des_0 = std::make_shared&lt;vp_nodes::vp_screen_des_node&gt;(<span class="stringliteral">&quot;screen_des_0&quot;</span>, 0);</div>
<div class="line">    <span class="keyword">auto</span> rtmp_des_0 = std::make_shared&lt;vp_nodes::vp_rtmp_des_node&gt;(<span class="stringliteral">&quot;rtmp_des_0&quot;</span>, 0, <span class="stringliteral">&quot;rtmp://192.168.77.60/live/10000&quot;</span>);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// construct pipeline</span></div>
<div class="line">    yunet_face_detector_0-&gt;attach_to({file_src_0});</div>
<div class="line">    sface_face_encoder_0-&gt;attach_to({yunet_face_detector_0});</div>
<div class="line">    osd_0-&gt;attach_to({sface_face_encoder_0});</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// auto split</span></div>
<div class="line">    screen_des_0-&gt;attach_to({osd_0});</div>
<div class="line">    rtmp_des_0-&gt;attach_to({osd_0});</div>
<div class="line"> </div>
<div class="line">    file_src_0-&gt;start();</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// for debug purpose</span></div>
<div class="line">    <a class="code hl_class" href="classvp__utils_1_1vp__analysis__board.html">vp_utils::vp_analysis_board</a> board({file_src_0});</div>
<div class="line">    board.<a class="code hl_function" href="classvp__utils_1_1vp__analysis__board.html#a5e9740a0c501610e5b84e548a5ad2178">display</a>();</div>
<div class="line">}</div>
<div class="ttc" id="a1-1-1__sample_8cpp_html_ae66f6b31b5ad750f1fe042a706a4e3d4"><div class="ttname"><a href="1-1-1__sample_8cpp.html#ae66f6b31b5ad750f1fe042a706a4e3d4">main</a></div><div class="ttdeci">int main()</div><div class="ttdef"><b>Definition</b> 1-1-1_sample.cpp:15</div></div>
<div class="ttc" id="aclassvp__utils_1_1vp__analysis__board_html"><div class="ttname"><a href="classvp__utils_1_1vp__analysis__board.html">vp_utils::vp_analysis_board</a></div><div class="ttdef"><b>Definition</b> vp_analysis_board.h:21</div></div>
<div class="ttc" id="aclassvp__utils_1_1vp__analysis__board_html_a5e9740a0c501610e5b84e548a5ad2178"><div class="ttname"><a href="classvp__utils_1_1vp__analysis__board.html#a5e9740a0c501610e5b84e548a5ad2178">vp_utils::vp_analysis_board::display</a></div><div class="ttdeci">void display(int interval=1, bool block=true)</div><div class="ttdef"><b>Definition</b> vp_analysis_board.cpp:64</div></div>
<div class="ttc" id="avp__logger_8h_html_a215e39f45255869a55a87042c9b13048"><div class="ttname"><a href="vp__logger_8h.html#a215e39f45255869a55a87042c9b13048">VP_LOGGER_INIT</a></div><div class="ttdeci">#define VP_LOGGER_INIT()</div><div class="ttdef"><b>Definition</b> vp_logger.h:128</div></div>
<div class="ttc" id="avp__logger_8h_html_a773398f3b7212c837d3996bd4a8ebc2d"><div class="ttname"><a href="vp__logger_8h.html#a773398f3b7212c837d3996bd4a8ebc2d">VP_SET_LOG_INCLUDE_THREAD_ID</a></div><div class="ttdeci">#define VP_SET_LOG_INCLUDE_THREAD_ID(_include_thread_id)</div><div class="ttdef"><b>Definition</b> vp_logger.h:114</div></div>
<div class="ttc" id="avp__logger_8h_html_a7b026e0cb7b1f5bcee94784c7c94a736"><div class="ttname"><a href="vp__logger_8h.html#a7b026e0cb7b1f5bcee94784c7c94a736">VP_SET_LOG_INCLUDE_CODE_LOCATION</a></div><div class="ttdeci">#define VP_SET_LOG_INCLUDE_CODE_LOCATION(_include_code_location)</div><div class="ttdef"><b>Definition</b> vp_logger.h:113</div></div>
</div><!-- fragment --><p> 上面代码运行后，会出现3个画面:</p><ol type="1">
<li>管道的运行状态图，状态自动刷新</li>
<li>屏幕显示结果（GUI）</li>
<li>播放器显示结果（RTMP）</li>
</ol>
<p><img src="./doc/p2.png" alt="" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md28"></a>
可以做哪些事情</h1>
<h2><a class="anchor" id="autotoc_md29"></a>
行为分析 &amp; 图片视频搜索</h2>
<p><img src="./doc/p6.png" alt="" class="inline"/> <img src="./doc/p7.png" alt="" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md30"></a>
案例原型</h1>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">id   </th><th class="markdownTableHeadNone">sample   </th><th class="markdownTableHeadNone">screenshot    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">1   </td><td class="markdownTableBodyNone">1-1-1_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p10.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">2   </td><td class="markdownTableBodyNone">1-1-N_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p11.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">3   </td><td class="markdownTableBodyNone">1-N-N_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p12.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">4   </td><td class="markdownTableBodyNone">N-1-N_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p13.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">5   </td><td class="markdownTableBodyNone">N-N_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p14.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">6   </td><td class="markdownTableBodyNone">paddle_infer_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p15.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">7   </td><td class="markdownTableBodyNone">src_des_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p16.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">8   </td><td class="markdownTableBodyNone">trt_infer_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p17.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">9   </td><td class="markdownTableBodyNone">vp_logger_sample   </td><td class="markdownTableBodyNone">-    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">10   </td><td class="markdownTableBodyNone">face_tracking_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p18.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">11   </td><td class="markdownTableBodyNone">vehicle_tracking_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p22.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">12   </td><td class="markdownTableBodyNone">interaction with pipe sample   </td><td class="markdownTableBodyNone">&ndash;    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">13   </td><td class="markdownTableBodyNone">record_sample   </td><td class="markdownTableBodyNone">&ndash;    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">14   </td><td class="markdownTableBodyNone">message_broker_sample &amp; message_broker_sample2   </td><td class="markdownTableBodyNone"><img src="./doc//p21.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">15   </td><td class="markdownTableBodyNone">mask_rcnn_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p30.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">16   </td><td class="markdownTableBodyNone">openpose_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p31.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">17   </td><td class="markdownTableBodyNone">enet_seg_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p32.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">18   </td><td class="markdownTableBodyNone">multi detectors and classifiers sample   </td><td class="markdownTableBodyNone"><img src="./doc//p33.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">19   </td><td class="markdownTableBodyNone">image_des_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p34.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">20   </td><td class="markdownTableBodyNone">image_src_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p35.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">21   </td><td class="markdownTableBodyNone">rtsp_des_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p36.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">22   </td><td class="markdownTableBodyNone">ba_crossline_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p37.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">23   </td><td class="markdownTableBodyNone">plate_recognize_sample   </td><td class="markdownTableBodyNone"><img src="./doc//p38.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">24   </td><td class="markdownTableBodyNone">vehicle body scan sample   </td><td class="markdownTableBodyNone"><img src="./doc/p40.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">25   </td><td class="markdownTableBodyNone">body scan and plate detect sample   </td><td class="markdownTableBodyNone"><img src="./doc/p39.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">26   </td><td class="markdownTableBodyNone">app_src_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p41.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">27   </td><td class="markdownTableBodyNone">vehicle cluster based on classify encoding sample   </td><td class="markdownTableBodyNone"><img src="./doc/p42.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">28   </td><td class="markdownTableBodyNone">ba_stop_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p49.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">29   </td><td class="markdownTableBodyNone">behaviour analysis   </td><td class="markdownTableBodyNone"><img src="./doc/p48.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">30   </td><td class="markdownTableBodyNone">similiarity search   </td><td class="markdownTableBodyNone"><img src="./doc/p44.png" alt="" class="inline"/><img src="./doc/p43.png" alt="" class="inline"/><img src="./doc/p45.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">31   </td><td class="markdownTableBodyNone">property and similiarity search   </td><td class="markdownTableBodyNone"><img src="./doc/p46.png" alt="" class="inline"/><img src="./doc/p47.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">32   </td><td class="markdownTableBodyNone">ba_jam_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p50.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">33   </td><td class="markdownTableBodyNone">face recognize   </td><td class="markdownTableBodyNone"><img src="./doc/p51.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">34   </td><td class="markdownTableBodyNone">license plate recognize(LPR) camera   </td><td class="markdownTableBodyNone"><img src="./doc/p52.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">35   </td><td class="markdownTableBodyNone">math expression check   </td><td class="markdownTableBodyNone"><img src="./doc/p53.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">36   </td><td class="markdownTableBodyNone">skip_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p54.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">37   </td><td class="markdownTableBodyNone">obstacle_detect_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p55.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">38   </td><td class="markdownTableBodyNone">firesmoke_detect_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p56.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">39   </td><td class="markdownTableBodyNone">face_swap_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p57.png" alt="" class="inline"/>    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">40   </td><td class="markdownTableBodyNone">video_restoration_sample   </td><td class="markdownTableBodyNone"><img src="./doc/p58.png" alt="" class="inline"/>   </td></tr>
</table>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.10.0
</small></address>
</body>
</html>
